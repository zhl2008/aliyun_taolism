## 基于决策树的恶意代码检测

by Hence Zhang@Lancet



### background and motivation

不久前，阿里云攻守道的第一场分站赛落下帷幕，而我们北航的Lancet战队也斩获了第三名的好成绩。除了1.5w的奖金外，我们还收获了大量分析恶意代码的经验，以及贴近实战的恶意代码的样本。比赛的形式大概是这样的，主办方给定180个左右的c语言项目，每个项目都可能是经过毒化，或者是安全的。被毒化的代码中会在某一个c文件的某一个函数中，放置后门函数。比赛要求选手找出其中恶意的文件名和函数并提交。

按照传统的思路，恶意代码检测主要有静态方法和动态方法两种，静态方法主要包括函数检测与字符串特征检测，动态方法一般要求将恶意代码编译成二进制文件，并在sandbox中调用，检测系统的函数调用和敏感文件的读写。因为限制了选手只有三个小时去审计所有的180个项目，所以逐个编译运行并不是一个理智的选择。因此，我们自行定义了一些敏感字符串和敏感函数，通过对C代码的CFG进行解析以及正则表达式的匹配，获得每个函数对于我们设立的规则的命中情况，最终在函数的粒度下，将所有的函数转换为具体的向量。

既然获得函数的向量，那么我们就可以根据某次比赛中标记好的数据集，使用机器学习算法去训练出一个智能的模型，能够通过给定的向量特征，判断出该向量特征对应的函数是否为malicious。之后，我们可以利用该模型，快速的筛选出可能存在问题的函数，并最终通过人工的判断，断言某个project中是否存在一个包含恶意函数的恶意文件。

在前两场比赛中，上述的过程都是依靠人工完成的，覆盖率低，漏报率高，且费事费力；在最后一场比赛中，我们使用了决策树的方法使用函数特征进行了训练，并预测了函数的恶意情况，取得了良好的成效。



### features selection

首先，我们通过对c源代码的CFG进行分析，以函数为基准得到了如下的信息：

1. 所有内部定义的函数列表
2. 每个内部函数中调用敏感函数的情况
3. 每个内部函数中的字符串正则匹配情况

我们通过我们的domain knowledges定义的敏感函数和敏感字符串如下所示：

```python
#0 file read functions
["read", "fread", "fgetc", "fgets","open","fopen"]

#1 file write functions
["write","fwrite", "fputc", "fputs", "fprintf","fscanf","sprintf"]

#2 keyboard logger functions
["tcgetattr"]

#3 socket operation functions
["send", "recv","connect","bind","socket","gethostbyname","recvfrom","inet_addr"]

#4 system command functions
["popen","system","exec","execl","execv","execve","execlp","execle","execvp"]

#5 file & env manipulate functions
["ftruncate", "chmod","ioctl","rename","putenv"]

#6 sensitive info functions
["ptrace","get_nprocs","opendir","readdir","lstat","getifaddrs","getlogin","getpwent","getuid","getcwd","getenv"]
```



敏感字符串，我们是使用正则表达式进行匹配：

```python 
#7 sensitive directory
/(etc|usr|var|proc|dev|home|root)

#8 sensitve file
(\.bash_history|\.bashrc|\.bash_profile|\.ssh|authorized_keys|rc\.d|cron\.d|\.conf|passwd)

#9 tmp directory
/tmp

#10 function call with string
((void|int|long)\s*\(\*\))

#11 network connection command
(( |\"|\'|\/|;)(wget|curl|mail)( |\"|\'))|(HTTP/1\.[1|0])

#12 IP address or port
([0-9]{1,3}\.){3}[0-9]{1,3}|htons\((\d){2,5}\)
  
#13  webshell
((((?:_POST|_GET|_REQUEST|GLOBALS)\[(?:.*?)\]\(\$(?:_POST|_GET|_REQUEST|GLOBALS)))|(((?:exec|base64_decode|edoced_46esab|eval|eval_r|system|proc_open|popen|curl_exec|curl_multi_exec|parse_ini_file|show_source|assert)\s*?\(\$(?:_POST|_GET|_REQUEST|GLOBALS)))|(((?:eval|eval_r|execute|ExecuteGlobal)\s*?\(?request))|((write|exec)\(request\.getParameter)|(((?:eval|eval_r|execute|ExecuteGlobal).*?request))|(SaveAs\(\s*?Server\.MapPath\(\s*?Request))

#14 advanced webshell
(disable_dynamic|AddType|x-httpd-php)

#15 linux command
(#define\s*.*\s*(popen|system|exec|execl|execv|execve|execlp|execle|execvp))

#16 linux system manipulate 
(( |\"|\'|\/|\.|;|\|)(chmod|chown|bash|cat|export|useradd)( |\"|\'))
  
#17 IP with confusion 
(\{((0x)?[0-9a-fA-F]{1,3},(\s)*){3}((0x)?[0-9a-fA-]{1,3})(\s)*\})

#18 confusion data
((\\x[0-9a-fA-F]{2}){3})|(\{((0x)?[0-9a-fA-F]{1,3},(\s)*){4,}((0x)?[0-9a-fA-]{1,3})(\s)*\})|(#define(\s)*_[0-9a-fA-F]{32})

#19 other evil strings
(( |\"|\'|\/)evil|( |\"|\'|\/|@)eval|shellcode|\* \* \*|( |\"|\'|\/)grep)

```



['read func','write func','keyboard func','socket func','cmd func','file&env mani func','info func','directory str','file str','tmp str','func call str','network str','ip/port str','webshell str', 'ad webshell str','cmd str','system mani str','confused IP str','confused data str','evil str']

针对以上规则，我们按照我们的domain knowledge做了一个简单的分类：

1. file read ： [0,4]         （文件读取）
2. Sensitive info : [2,6,7,8,9,13,14,18]    (sensitive filename, dir, content)
3. File write: [1,4,15]               （文件写 + 命令执行）
4. network： [3,4,11,12,15,17,18]    (网络传输)
5. Others:  [4,5,15,16,18,19]     （单个存在 即有一定的可能性是恶意的）

其中file read/file write/sensitive info/network 组合存在时，才认为是恶意的，而others中的规则如果单独匹配多次，也可以认为是恶意的。总共的特征有20个维度。



### 数据清洗

在使用我们的程序对所有project的所有函数处理之后，我们得到了一个包含所有函数向量特征的文件，以及一个主办方提供的恶意函数的参考文件。我们由此生成适合于我们输入的数据：



```python
a = open('malicious.txt').readlines()
b = open('func_status.txt').readlines()
tmp = []
for entry in b:
    if entry in a:
        tmp.append(entry.strip() + ",1")
    else:
        tmp.append(entry.strip() + ",0")
```

但是此时，我们数据中的正例和反例的比例严重失调，正例的数量仅仅占总样本数的2%左右，所有我们需要对已有的正例进行重复（在某些算法中也可以增加正例判为反例的惩罚因子）

```python
record_x = []
record_y = []
malicious_x = []
for entry in tmp:
    if '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0' not in entry:
        t = [int(i) for i in entry.split(',')[3:-1]]
        record_x.append(t)
        if int(entry.split(',')[-1]) == 1:
            record_y.append(1)
            malicious_x.append([int(i) for i in entry.split(',')[3:-1]])
        else:
            record_y.append(0)
```



此时我们得到6926个样本，其中1342个整理，5584个反例。但此时，正例的样本数量仍然不能满足我们的要求，而且主办方提供的样本对恶意代码特征的覆盖率太小，因此，我决定用domain knowledge去生成一些数据，以此让machine能够学习到这一部分的domain knowledge。因为我们的函数特征来源于恶意代码，而对恶意代码的判断这样的经验往往是合适的：恶意代码应当有完整的操作链，在action和intention上都要体现其恶意性。因此，在我们粗略地定义了不同的column对应的语义后，我们对恶意代码可能的语义组合做了一个定义：

1. read sensetive info and write
2. read sensetive info and sendout
3. write sensetive info
4. recv the info and write to sensetive
5. read sensetive and send out

于此同时，我们也定义了一系列非恶意的语义用于对比，以方便能将我们的domain knowledge通过对比的形式植入到我们训练的模型中去。

```python
'''
    we try to generate some of the malicious data, to ensure that: the amount of  positive 
    instances and that of negative instance should be equivalent  
  
'''
def random_data(rows,score):
    my_score = 30
    tmp = [0 for i in range(len(record_x[0]))]
    for row in rows:
        tmp[row] = randint(1,5)
    
    
    # if score=0, do not genrate the 1 in other row
    if score==1:
        for i in range(len(record_x[0])):
            # add some extra random features
            if tmp[i] == 0 and randint(1,5)%5==0:
                tmp[i] = 1
    
    
    return tmp + [score]

def record_append(rows,score,number):
    global record_x,record_y
    for i in range(number):
        data = random_data(rows,score)
        record_x.append(data[:-1])
        record_y.append(data[-1])

def get_rand(array):
    return array[randint(0,len(array)-1)]
        
def generate_data(my_type):

    read = [0,4]                                   # read file / get sensetive info
    sensetive_info = [2,6,7,8,9,13,14,18]          # sensetive dir/file/systeminfo
    write = [1,4,15]                               # write file/system config/webshell
    out = [3,4,11,12,15,17,18]                     # output to socket/ip/network/webshell/tmp file
    other = [4,5,15,16,18,19]                      # pick it by random
    
    my_choice = []
    
    # malicious
    if my_type == 1:
        my_choice = map(get_rand,[read,sensetive_info,write])   #read sensetive info and write
    elif my_type == 2:
        my_choice = map(get_rand,[read,sensetive_info,out])     #read sensetive info and sendout
    elif my_type == 3:
        my_choice = map(get_rand,[write,sensetive_info])        # write sensetive info 
    elif my_type == 4:
        my_choice = map(get_rand,[write,sensetive_info,out])    # recv the info and write to sensetive 
    elif my_type == 5:
        my_choice = map(get_rand,[read,out])                    # read sensetive and out
    
    # not malicious
    elif my_type == 6:                                          
        my_choice = map(get_rand,[read,sensetive_info])
    elif my_type == 7:
        my_choice = map(get_rand,[write])
    elif my_type == 8:
        my_choice = map(get_rand,[out])
    elif my_type == 9:
        my_choice = map(get_rand,[read])
    elif my_type == 10:
        my_choice = map(get_rand,[sensetive_info])
            
    my_choice = set(my_choice)
    if my_type<=5 and len(my_choice) == 1 and 18 not in my_choice:
        # do it again
        generate_data(my_type)
        return
    if my_type > 5:
        for i in range(20):
            record_append(my_choice,1,10) 
    else:
        for i in range(10):
            record_append(my_choice,0,10)
    

# generate 2000 entries of malicious
generate_data(1)
generate_data(1)
generate_data(2)
generate_data(2)
generate_data(3)
generate_data(3)
generate_data(4)
generate_data(4)
generate_data(5)
generate_data(5)

# generate 500 entries of non-malicious
generate_data(6)
generate_data(7)
generate_data(8)
generate_data(9)
generate_data(10)

record_x = np.array(record_x)
record_y = np.array([int(i) for i in record_y])
malicious_x = np.array(malicious_x)
record_x,record_y = shuffle(record_x,record_y)
open('record.txt','w').write('')
for i in range(len(record_x)):
    record = ','.join([str(j) for j in record_x[i]]) + ',' + str(record_y[i])
    open('record.txt','a').write(record+"\n")
```

此时，我们可以在record.txt 中得到我们的处理后的数据。总共有8926条记录，其中正例有2342条记录，反例有6584条记录，基本符合我们数据需求。



### 算法选择与训练

由于在我们本次训练的数据有很强的关联性，在单个语义元素出现时非恶意，而一旦特定的语义出现后，则判定为恶意代码。有这种组合式、递进的关系我们可以联想到树的结构，因此，此处我们使用decision tree的算法来对建立模型。

我们将现有的数据混洗，然后从中抽取7000条作为训练数据集，将剩余的数据作为测试集。

选择测试集和训练集：

```python
print(len(record_y))
print(len(record_x))
tmp = [y for y in record_y if y==1]
len(tmp)

# test data set
train_x = record_x[:7000]
train_y = record_y[:7000]

# train data set
test_x = record_x[7000:]
test_y = record_y[7000:]
```

模型我们使用CART算法，用基尼系数来作为属性选择的依据，为了防止决策树过拟合的问题，根据经验将decision tree的最大深度限制为7，叶子节点终止划分的最小叶节点大小为5。此外，为了提高恶意函数的覆盖率，我们提升代码恶意的权重。

```python
clt = tree.DecisionTreeClassifier(splitter='best',max_depth=7,min_samples_leaf=5,class_weight={0:0.18,1:0.82})
clt.fit(train_x,train_y)
predict_y= clt.predict(test_x)
```

再使用训练集训练模型，得出结果，并与真实值进行比较，获取到四个关键的评估参数：

FRR，FAR，TAR，TRR

```python
true_accept = 0
true_reject = 0
false_accept = 0
false_reject = 0

true_total = len([y for y in test_y if y==1])
false_total = len([y for y in test_y if y==0])

total = len(predict_y)
for i in range(total):
    if predict_y[i] == 1 and test_y[i] == 1:
        true_accept += 1
    if predict_y[i] == 1 and test_y[i] == 0:
        false_accept += 1
    if predict_y[i] == 0 and test_y[i] == 0:
        true_reject += 1
    if predict_y[i] == 0 and test_y[i] == 1:
        false_reject += 1
        
print('TAR: %f' %(true_accept*100/true_total))
print('FRR: %f' %(false_reject*100/true_total))
print('TRR: %f' %(true_reject*100/false_total))
print('FAR: %f' %(false_accept*100/false_total))
```

最终使用测试集测试的结果为：

> TAR: 97.933884
> FRR: 2.066116
> TRR: 89.667129
> FAR: 10.332871



我们还可以使用python的一些扩展库对于训练出的decision tree进行可视化：

```python
from IPython.display import Image  
import pydotplus 
dot_data = tree.export_graphviz(clt, out_file=None, 
                         feature_names=['read func','write func','keyboard func','socket func','cmd func','file&env mani func','info func','directory str','file str','tmp str','func call str','network str','ip/port str','webshell str', 'ad webshell str','cmd str','system mani str','confused IP str','confused data str','evil str'],  
                         class_names=['good','bad'],  
                         filled=True, rounded=True,  
                         special_characters=True)  
graph = pydotplus.graph_from_dot_data(dot_data)  
Image(graph.create_png())
```

可视化效果如下所示：
![decision_tree](/Users/haozigege/Desktop/ctf/softsec/aliyun_taolism/ML/decision_tree.png)



### 模型预测效果

我们按照之前的方法对需要进行预测的数据进行清洗，需要预测的数据来源于另外一场比赛：

```python
a = open('malicious_1.txt').readlines()
b = open('func_status_1.txt').readlines()
tmp = []
for entry in b:
    if entry in a:
        tmp.append(entry.strip() + ",1")
    else:
        tmp.append(entry.strip() + ",0")
new_x = []
new_y = []
new_malicious_x = []
for entry in tmp:
    if '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0' not in entry:
        t = [int(i) for i in entry.split(',')[3:-1]]
        new_x.append(t)
        if int(entry.split(',')[-1]) == 1:
            new_y.append(1)
            new_malicious_x.append([int(i) for i in entry.split(',')[3:-1]])
        else:
            new_y.append(0)
            
new_x = np.array(new_x)
new_y = np.array([int(i) for i in new_y])
new_malicious_x = np.array(new_malicious_x)
new_x,new_y = shuffle(new_x,new_y)
open('record_predict_1.txt','w').write('')
for i in range(len(new_x)):
    record = ','.join([str(j) for j in new_x[i]]) + ',' + str(new_y[i])
    open('record_predict_1.txt','a').write(record+"\n")
   
```



然后我们使用真实数据作为输入，并预测预测：

```python
new_predict_y = clt.predict(new_x)
```



最终的预测的结果与比赛的真实结果的对比如下所示：

> TAR: 87.254902
> FRR: 12.745098
> TRR: 92.053643
> FAR: 7.946357

可以看到恶意代码的覆盖率TAR接近90%， 而误报率FAR仅有7.9%。通过决策树得到的效果相当好。





### 结果分析与总结

在使用decision tree去处理这样一个实际问题的过程中，遇到了很多细节处理的问题，也在模型与算法选择中不断权衡与反复考量。在整个工程的数据清洗到建模，最终到检验的过程中，我主要的收获有以下几点：

1. 什么样的问题适合用机器学习的算法去解决以及如何将问题转化为适合机器学习算法解决的问题的问题；
2. 如何清洗数据，在数据量过小，或数据量不平衡的情况下如何处理；
3. 如何去调试现有模型中的一些超参数，让模型“多快好省”。

但是，还是有一些不足之处亟待以后的改进：

1. 数据生成的地方是否应当引入一定的随机性？
2. 因为比赛过程中一个工程内最多只有一个恶意函数，那么，如何在判定的恶意函数中自动选择出最终的结果？
3. 如果引入评分系统，而不是简简单单的进行二分类，那么，如何通过decision tree进行评分？
4. 如果使用叶子节点的正反例数的比例来给函数特征评分，那么这种方式是否具有稳定性和可靠性？
5. 如何上述方法可行，那么我们如何通过sklearn的接口获取到这样的评分？